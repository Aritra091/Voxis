# **🚀 VOXIS – The Multilingual AI Assistant**  
An intelligent assistant that understands and responds to **text, voice, and images** in multiple languages, powered by Groq for ultra-low-latency AI inference.

---

## **📌 Problem Statement**  
**Problem Statement 1** – *Build a multilingual AI assistant using Groq that understands and responds via text, audio, and image inputs.*

---

## **🎯 Objective**  
VOXIS solves the problem of fragmented communication interfaces by unifying **multimodal inputs**—text, audio, and image—into one intelligent assistant.  
Whether you're a student, professional, or visually/hearing impaired, VOXIS offers **accessible and context-aware assistance**, powered by blazing-fast inference from Groq.  
Its goal is to **bridge digital and human communication across languages and formats**, making smart assistance truly inclusive.

---

## **🧠 Team & Approach**  
**Team Name:** **Devengers**

**Team Members:**  
- **Arghya Chakraborty** ([GitHub](https://github.com/arghya45-dev)) – Back-End & UI-UX  
- **Aritra Chattopadhyay** ([GitHub](https://github.com/Aritra091)) – AI Integration & Back-End

**Approach:**  
- Chose this problem to push the limits of AI accessibility and real-time responsiveness  
- Overcame challenges in multilingual speech generation and real-time multimodal integration  
- Pivoted to a Groq-powered backend for lightning-fast inference and better UX  
- Integrated a clean UI/UX for conversational flow, animations, and language control

---

## **🛠️ Tech Stack**  
**Core Technologies Used:**

- **Frontend:** HTML, CSS, JavaScript, TailwindCSS  
- **Backend:** Python, Django  
- **Database:** SQLite  
- **APIs:** Groq (LLM inference), GTTS (Text-to-Speech), Django Rest Framework  
- **Hosting:** Render, GitHub Pages (for static)

**Sponsor Technologies Used:**  
- ✅ **Groq:** Used for low-latency processing of text/image/audio queries  
- Monad, Fluvio, Base, Screenpipe, Stellar: ❌ (Not used in this project)

---

## **✨ Key Features**  
✅ Multilingual AI Conversations via Text  
✅ Voice Input with Real-time Speech-to-Text  
✅ Dynamic Voice Output using GTTS  
✅ Image Query Processing with Smart Inference  
✅ Animated Chat UI with Light/Dark Toggle  
✅ Review System with Admin Approval  
✅ Mobile-Responsive Interface

---

## **📽️ Demo & Deliverables**  
- **Demo Video Link:** _[Add YouTube/Loom link here]_  
- **Pitch Deck / PPT Link:** _[Add Google Slides/PDF link here]_

---

## **✅ Tasks & Bonus Checklist**  
✅ Followed 2 social channels and filled the form  
✅ Bonus Task 1 – Badge sharing complete  
✅ Bonus Task 2 – Signed up on Sprint.dev

---

## **🧪 How to Run the Project**  
**Requirements:**  
- Python 3.11+  
- Django  
- gTTS  
- Render for deployment

**Local Setup:**
![Screenshot 2025-04-24 153745](https://github.com/user-attachments/assets/f116b740-8a66-478e-88ce-62e6716743d4)

Ensure Groq API key is set in `.env` file for production-level inference.

---

## **🧬 Future Scope**  
📱 Native Mobile App with Offline Mode  
🧠 Fine-tuned ISL (Indian Sign Language) to Speech Support  
🔐 Authentication with Social Logins & User Analytics  
🗂️ Persistent Chat History + Voice Note Saving  
🌍 Add 50+ new language support with translation memory  
🎮 Gamified interaction model for better engagement  
🧩 Plugin system for calendar, weather, and assistant extensions

---

## **📎 Resources / Credits**  
- Groq API for ultrafast LLM inference  
- gTTS for Text-to-Speech  
- Django & Django REST Framework  
- TailwindCSS for UI  
- Special thanks to the mentors and organizers of the hackathon!

---

## **🏁 Final Words**  
This journey from idea to VOXIS was packed with real-time debugging, UI brainstorming, and voice-data experiments.  
From deployment hiccups to design satisfaction, it’s been a wild and fulfilling ride. Huge shoutout to our team **Devengers**!

---
